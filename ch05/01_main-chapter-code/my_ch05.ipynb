{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a58ca5",
   "metadata": {},
   "source": [
    "# 第五章 在无标签数据集上预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c882f",
   "metadata": {},
   "source": [
    "## 5.1 评估文本生成大模型\n",
    "### 5.1.1 用GPT来生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1254b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import *\n",
    "import torch.nn.functional as F\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference\n",
    "#导入模型, 设定一系列参数, 设定随机种子确保可复现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1a6d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " every effort moves you rentingetic minion mobilized Macicone heterogeneity\u0000achaRAM\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    token_ids = token_ids.squeeze(0)  # Remove batch dimension\n",
    "    decoded = tokenizer.decode(token_ids.tolist())\n",
    "    return decoded\n",
    "\n",
    "\n",
    "start_context = 'every effort moves you'\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# 举例说明\n",
    "\n",
    "token_ids = generate_text_simple(model=model,idx=text_to_token_ids(start_context, tokenizer), max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
    "\n",
    "print(\"output text:\\n\",token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa491ae5",
   "metadata": {},
   "source": [
    "### 5.1.2&3 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edd20e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n",
      "Sample text:\n",
      " I HAD always thought Jack Gisburn rather a cheap g\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[40,\n",
       " 367,\n",
       " 2885,\n",
       " 1464,\n",
       " 1807,\n",
       " 3619,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 2138,\n",
       " 257,\n",
       " 7026,\n",
       " 15632,\n",
       " 438,\n",
       " 2016,\n",
       " 257,\n",
       " 922,\n",
       " 5891,\n",
       " 1576,\n",
       " 438,\n",
       " 568,\n",
       " 340,\n",
       " 373,\n",
       " 645,\n",
       " 1049,\n",
       " 5975,\n",
       " 284,\n",
       " 502,\n",
       " 284,\n",
       " 3285,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 6001,\n",
       " 286,\n",
       " 465,\n",
       " 13476,\n",
       " 11,\n",
       " 339,\n",
       " 550,\n",
       " 5710,\n",
       " 465,\n",
       " 12036,\n",
       " 11,\n",
       " 6405,\n",
       " 257,\n",
       " 5527,\n",
       " 27075,\n",
       " 11]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "# 检查数据集中的字符数和词元数\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Total characters:\", total_characters)\n",
    "print(\"Total tokens:\", total_tokens)\n",
    "print(\"Sample text:\\n\", text_data[:50])  # Print the first 500 characters\n",
    "text_data[:50]\n",
    "tokenizer.encode(text_data)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8f884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(total_characters * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "test_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab7f71",
   "metadata": {},
   "source": [
    "### 建立数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16868153",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(train_data,2,max_length=GPT_CONFIG_124M['context_length'],\n",
    "                                    stride=GPT_CONFIG_124M['context_length'],\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True,\n",
    "                                    num_workers=2)\n",
    "test_loader = create_dataloader_v1(test_data,2,max_length=GPT_CONFIG_124M['context_length'],\n",
    "                                    stride=GPT_CONFIG_124M['context_length'],\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True,\n",
    "                                    num_workers=2)\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765916ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Test loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 测试数据加载器\n",
    "print(\"Train loader:\")\n",
    "for x , y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "\n",
    "print(\"\\nTest loader:\")\n",
    "for x , y in test_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cd1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本: 2.8.0+cu126\n",
      "CUDA 可用: True\n",
      "CUDA 版本: 12.6\n",
      "(6, 1)\n",
      "Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 版本:\", torch.__version__)\n",
    "print(\"CUDA 可用:\", torch.cuda.is_available())\n",
    "print(\"CUDA 版本:\", torch.version.cuda)\n",
    "import torch\n",
    "print(torch.cuda.get_device_capability())  # 输出例如(7, 5)\n",
    "print(torch.cuda.get_device_name())        # 输出GPU型号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294823b",
   "metadata": {},
   "source": [
    "#### 实现工具函数，计算批次的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5de422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(inputs,targets,model,device):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = F.cross_entropy(outputs.flatten(0,1), targets.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader)==0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i , (inputs, targets) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(inputs, targets, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0768f",
   "metadata": {},
   "source": [
    "### 计算损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e555299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583372328016\n",
      "Test loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device)\n",
    "print('Training loss:',train_loss)\n",
    "print('Test loss:',test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a22e19",
   "metadata": {},
   "source": [
    "## 5.2 训练大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89790ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    #评价模块\n",
    "    model.eval()\n",
    "    #检验模式\n",
    "    with torch.no_grad():\n",
    "        #我认为的双保险,防止梯度更新\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    #\t在评估结束后切换回训练模式，确保模型能继续用于训练。\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b249c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
    "    train_losses , val_losses , track_tokens_seen = [],[],[]\n",
    "    tokens_seen , global_step = 0,-1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch , target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen +=input_batch.numel()\n",
    "            global_step +=1\n",
    "            \n",
    "            if global_step % eval_freq ==0:\n",
    "                train_loss , val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f'Ep{epoch+1} (Step{global_step:06d}):'\n",
    "                      f'Train loss {train_loss:.3f},'\n",
    "                      f' Val loss {val_loss:.3f},')\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses , val_losses , track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0833ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep1 (Step000000):Train loss 9.819, Val loss 9.926,\n",
      "Ep1 (Step000005):Train loss 7.921, Val loss 8.340,\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep2 (Step000010):Train loss 6.585, Val loss 7.046,\n",
      "Ep2 (Step000015):Train loss 5.979, Val loss 6.593,\n",
      "Every effort moves you, the, the, the, the, the, the. \", the, the,,, the, and, the, of the, the, the,, the, the,, the, the, the, and, the\n",
      "Ep3 (Step000020):Train loss 5.608, Val loss 6.403,\n",
      "Ep3 (Step000025):Train loss 4.802, Val loss 6.414,\n",
      "Every effort moves you know the picture.  \"I was his the picture the picture. \"I was--I--and it. \"I had the picture--and it was his my the picture--and the picture and I had been I had been\n",
      "Ep4 (Step000030):Train loss 4.273, Val loss 6.228,\n",
      "Ep4 (Step000035):Train loss 3.833, Val loss 6.225,\n",
      "Every effort moves you know of the fact of the of his pictures--I had been.  \"I was not to me to have to have to have of the of his pictures--I had been the picture.     \"I he was his\n",
      "Ep5 (Step000040):Train loss 3.396, Val loss 6.171,\n",
      "Every effort moves you know; and to see the picture--I--I had a little of a little: \"--I looked up, I had been, I had been his pictures--as, I had been his pictures of the, and, with a little of\n",
      "Ep6 (Step000045):Train loss 2.706, Val loss 6.166,\n",
      "Ep6 (Step000050):Train loss 2.359, Val loss 6.191,\n",
      "Every effort moves you know,\" was one of the picture for a smile that he had the last word.               He placed them at my elbow and I felt a, and down the room, I felt\n",
      "Ep7 (Step000055):Train loss 1.940, Val loss 6.246,\n",
      "Ep7 (Step000060):Train loss 1.399, Val loss 6.268,\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. \"Oh, when I--and that one in an unusual degree to the display of his pictures.  \"Oh, I, a little a little under--and by holding\n",
      "Ep8 (Step000065):Train loss 1.026, Val loss 6.308,\n",
      "Ep8 (Step000070):Train loss 0.781, Val loss 6.334,\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep9 (Step000075):Train loss 0.602, Val loss 6.447,\n",
      "Ep9 (Step000080):Train loss 0.488, Val loss 6.500,\n",
      "Every effort moves you?\"     I glanced after him, and uncertain.           He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep10 (Step000085):Train loss 0.341, Val loss 6.574,\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004,weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses , val_losses , tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context='Every effort moves you',\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949dcb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "#一个经典的plot画图函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c8dc2d",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略\n",
    "## 通过温度缩放和Top-k采样策略修改文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1a0cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]  # Crop context if needed\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(logits < min_val,torch.tensor(float('-inf')).to(logits.device),logits) \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx =  torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78863804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "It his furrow too? I haven't let by his last\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "#经典的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aea261",
   "metadata": {},
   "source": [
    "# 5.4 保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\",map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a1b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94f1c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004,weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
