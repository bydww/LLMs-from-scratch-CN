{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077dadd6",
   "metadata": {},
   "source": [
    "# 从零实现GPT模型进行文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1d202d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim':768,\n",
    "    'n_heads':12,\n",
    "    'n_layers':12,\n",
    "    'drop_rate':0.1,\n",
    "    'qkv_bias':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc1721aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e92796",
   "metadata": {},
   "source": [
    "## 4.2 使用归一化层进行归一化激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c455240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义归一化层\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        var = x.var(-1,keepdim=True,unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return x * self.scale + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729f119",
   "metadata": {},
   "source": [
    "## 4.3 实现GELU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a6b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8225e2a",
   "metadata": {},
   "source": [
    "# 4.4 带GELU激活函数的前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3aab38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'],cfg['emb_dim']),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd01b8d",
   "metadata": {},
   "source": [
    "## 4.5 连接Transformer块中的注意力层和线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "466307b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.ln2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.attn = MultiHeadAttention(d_in = cfg['emb_dim'], d_out = cfg['emb_dim'], \n",
    "                                           context_length = cfg['context_length'], \n",
    "                                           dropout = cfg['drop_rate'], \n",
    "                                           num_heads = cfg['n_heads'], qkv_bias = False)\n",
    "        self.ffn = FeedForward(cfg)\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "    def forward(self,x):\n",
    "        shortcut = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.attn(x)\n",
    "        x= self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.ffn(x)\n",
    "        x= self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966d64d",
   "metadata": {},
   "source": [
    "## 4.6 实现GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5338413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'],cfg['vocab_size'],bias=False)\n",
    "    def forward(self, x):\n",
    "        tok_emb = self.tok_emb(x)\n",
    "        pos_emb = self.pos_emb(torch.arange(x.size(1),device=x.device))\n",
    "        input_emb = tok_emb + pos_emb\n",
    "        input_emb = self.drop_emb(input_emb)\n",
    "        x = self.trf_blocks(input_emb)\n",
    "        x = self.final_norm(x)\n",
    "        return self.out_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31495358",
   "metadata": {},
   "source": [
    "### 测试GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e58ba0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100,   345],\n",
      "        [16833,  1110,  6622,   257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "text1 = 'every effort moves you'\n",
    "text2 = 'every day holds a'\n",
    "batch.append(torch.tensor(tokenizer.encode(text1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text2)))\n",
    "batch = torch.stack(batch,dim=0)  # (B,T)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93931f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3640, -0.5654,  0.4703,  ..., -0.4383, -0.0280, -0.4681],\n",
      "         [ 0.1578, -0.2142,  0.7080,  ..., -0.0916, -0.0604, -0.7349],\n",
      "         [-0.3492,  0.6082,  0.2345,  ...,  0.7863,  0.0706, -0.7593],\n",
      "         [ 0.1236,  0.6927,  0.3464,  ...,  0.0312, -0.8640, -0.0684]],\n",
      "\n",
      "        [[ 0.3428, -0.2037, -0.3596,  ..., -0.8504, -0.2254, -0.4678],\n",
      "         [ 0.6280,  0.2062,  0.1321,  ..., -0.2014, -0.1827, -0.6977],\n",
      "         [-0.3165,  0.9189,  0.6268,  ...,  1.3942,  0.0910,  1.0845],\n",
      "         [-0.5646, -0.3015,  1.6866,  ...,  0.3215, -0.3524, -0.9673]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(out.shape)  # (B,T,V)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ab3abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 163009536\n",
      "Total size (MB): 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# 统计模型总参数量\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "total_size_bytes = total_params * 4  # assuming float32\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total size (MB): {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedfa5b",
   "metadata": {},
   "source": [
    "# 4.7 生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5356c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        probas = torch.softmax(logits,dim=-1)\n",
    "        idx_next = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "        idx = torch.cat((idx,idx_next),dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fed4eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [16833, 3626, 1312, 765]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_text = \"every effort i want\"\n",
    "encoded = tokenizer.encode(start_text)\n",
    "print('encoded:' ,encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # (1, T)\n",
    "print('encoded_tensor.shape:' ,encoded_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df3a9f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape: torch.Size([1, 10])\n",
      "out length:  10\n",
      "生成文本: every effort i wantologic wealth Anxiety Amtrak incomes prescribe\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(model,encoded_tensor,max_new_tokens=6,context_size=1024)\n",
    "print('out.shape:' ,out.shape)\n",
    "print('out length: ' ,len(out[0]))\n",
    "print('生成文本:' ,tokenizer.decode(out[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czc_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
